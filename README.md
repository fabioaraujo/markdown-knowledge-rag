# KB-RAG - Base de Conhecimento com RAG

Sistema RAG (Retrieval-Augmented Generation) para criar uma base de conhecimento inteligente usando arquivos Markdown como fonte.

**âœ¨ Funciona 100% local com LM Studio ou na nuvem com OpenAI!**

## ğŸš€ CaracterÃ­sticas

- ğŸ“ Usa arquivos Markdown como fonte de conhecimento
- ğŸ  **100% Local com LM Studio** (privacidade total!)
- â˜ï¸ Ou use OpenAI para velocidade mÃ¡xima
- ğŸ” Busca semÃ¢ntica usando embeddings
- ğŸ¤– Respostas contextualizadas com LLM
- ğŸ“š CitaÃ§Ã£o de fontes
- ğŸ’¾ PersistÃªncia do banco vetorial (ChromaDB)
- ğŸš« Sem custos (modo local)

## ğŸ“¦ InstalaÃ§Ã£o

Este projeto usa [uv](https://github.com/astral-sh/uv) para gerenciamento de dependÃªncias.

```

### OpÃ§Ã£o 1: LM Studio (Local - Recomendado) ğŸ 

1. **Instale o LM Studio**: https://lmstudio.ai/
2. **Baixe um modelo** (ex: Mistral-7B, Llama-3.2, Phi-3)
3. **Inicie o servidor** no LM Studio
4. **Pronto!** Rode `uv run kb_rag.py`

ğŸ“– Guia completo: [LMSTUDIO.md](LMSTUDIO.md)

### OpÃ§Ã£o 2: OpenAI (Cloud) â˜ï¸

```bash
cp .env.example .env
# Edite .env e adicione sua OPENAI_API_KEY
```

No cÃ³digo, use `provider="openai"Configurar API key
cp .env.example .env
# Edite .env e adicione sua OPENAI_API_KEY
```

## ğŸ¯ Uso

### Adicionar documentos

Coloque seus arquivos `.md` na pasta `docs/`:

```
docs/
â”œâ”€â”€ conceitos.md
â”œâ”€â”€ tutoriais.md
â””â”€LM Studio (Local)
kb = KnowledgeBaseRAG(
    docs_path="./docs",
    provider="lmstudio",  # ğŸ‘ˆ Modo local!
    lmstudio_url="http://localhost:1234/v1",
    embedding_model="all-MiniLM-L6-v2"
)

# OU OpenAI (Cloud)
kb = KnowledgeBaseRAG(
    docs_path="./docs",
    provider="openai"  # ğŸ‘ˆ Modo cloud
)

# Configurar

```bash
uv run kb_rag.py
```

### Uso programÃ¡tico

```pSentence-Transformers**: Embeddings locais (nÃ£o precisa de API)
- **OpenAI** (opcional): API para embeddings e LLM na cloud
from kb_rag import KnowledgeBaseRAG

# Inicializar
kb = KnowledgeBaseRAG(docs_path="./docs")

# Configurar (primeira vez ou force_rebuild=True)
kb.setup(force_rebuild=False)

# Fazer consulta
resultado = kb.query("Como funciona o sistema RAG?")
print(resultado['result'])
```

## ğŸ› ï¸ Estrutura

- `kb_rag.py` - CÃ³digo principal do sistema RAG
- `docs/` - Seus arquivos Markdown de conhecimento
- `chroma_db/` - Banco vetorial persistido (gerado automaticamente)
- `.env` - ConfiguraÃ§Ã£o da API key

## ğŸ“ DependÃªncias

- **LangChain**: Framework para construÃ§Ã£o de aplicaÃ§Ãµes com LLMs
- **ChromaDB**: Banco vetorial para armazenamento de embeddings
- **OpenAI**: API para embeddings e LLM

## ğŸ’¡ Exemplo

```python
kb = KnowledgeBaseRAG()
kb.setup()

# Consulta
resultado = kb.query("O que Ã© RAG?")
print(resultado['result'])
# SaÃ­da: RAG (Retrieval-Augmented Generation) Ã© uma tÃ©cnica...

# Ver fontes
for doc in resultado['source_documents']:
    print(f"- {doc.metadata['source']}")
```

## ğŸ”„ Atualizar Base de Conhecimento

ApÃ³s adicionar/modificar arquivos na pasta `docs/`:

```python
kb.setup(force_rebuild=True)  # ReconstrÃ³i o banco vetorial
```

## ğŸ“„ LicenÃ§a

MIT
