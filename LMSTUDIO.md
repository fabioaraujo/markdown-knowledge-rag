# üè† Usando LM Studio (IA Local)

Este projeto suporta **LM Studio** para rodar a IA completamente local, sem precisar de API keys ou internet!

## üöÄ Configura√ß√£o do LM Studio

### 1. Instalar LM Studio
- Baixe em: https://lmstudio.ai/
- Instale e abra o programa

### 2. Baixar um Modelo
Recomenda√ß√µes de modelos:

**Modelos leves (4-8GB RAM):**
- `Phi-3-mini` (3.8B par√¢metros)
- `TinyLlama` (1.1B par√¢metros)

**Modelos m√©dios (16GB RAM):**
- `Mistral-7B-Instruct`
- `Llama-3.2-7B-Instruct`

**Modelos poderosos (32GB+ RAM):**
- `Mixtral-8x7B-Instruct`
- `Llama-3.1-13B-Instruct`

### 3. Iniciar o Servidor
1. No LM Studio, v√° em **"Local Server"**
2. Selecione o modelo baixado
3. Clique em **"Start Server"**
4. Servidor iniciar√° em: `http://localhost:1234`

## üíª Configura√ß√£o do Projeto

### Instalar depend√™ncias
```bash
uv sync
```

### Executar com LM Studio
```python
from kb_rag import KnowledgeBaseRAG

kb = KnowledgeBaseRAG(
    docs_path="./docs",
    provider="lmstudio",
    lmstudio_url="http://localhost:1234/v1",
    embedding_model="all-MiniLM-L6-v2"
)

kb.setup()
kb.query("Sua pergunta aqui")
```

### Ou simplesmente rode:
```bash
uv run kb_rag.py
```

O c√≥digo j√° est√° configurado para usar LM Studio por padr√£o!

## üéØ Vantagens

‚úÖ **100% Local** - Sem enviar dados para cloud  
‚úÖ **Privacidade Total** - Seus documentos n√£o saem do computador  
‚úÖ **Sem Custos** - N√£o precisa de API keys pagas  
‚úÖ **Funciona Offline** - Ap√≥s baixar os modelos  

## ‚öôÔ∏è Embeddings Locais

O sistema usa **sentence-transformers** para gerar embeddings localmente:
- Modelo padr√£o: `all-MiniLM-L6-v2` (apenas 80MB!)
- R√°pido e eficiente
- Qualidade compar√°vel ao OpenAI para portugu√™s

Outros modelos dispon√≠veis:
- `paraphrase-multilingual-MiniLM-L12-v2` (melhor para portugu√™s)
- `all-mpnet-base-v2` (mais preciso, mas maior)

Para trocar o modelo:
```python
kb = KnowledgeBaseRAG(
    embedding_model="paraphrase-multilingual-MiniLM-L12-v2"
)
```

## üîÑ Alternando entre OpenAI e LM Studio

```python
# LM Studio (local)
kb = KnowledgeBaseRAG(provider="lmstudio")

# OpenAI (cloud)
kb = KnowledgeBaseRAG(provider="openai")
```

## üìä Performance

| Provider | Velocidade | Custo | Privacidade |
|----------|------------|-------|-------------|
| LM Studio | Depende do hardware | Gr√°tis | 100% Local |
| OpenAI | Muito r√°pido | ~$0.002/1K tokens | Cloud |

## üêõ Troubleshooting

**Erro de conex√£o:**
- Verifique se o LM Studio est√° rodando
- Confirme a URL: `http://localhost:1234`

**Respostas lentas:**
- Use modelos menores (Phi-3, TinyLlama)
- Verifique se tem GPU dispon√≠vel

**Erro de mem√≥ria:**
- Escolha modelo menor
- Reduza `chunk_size` no c√≥digo
